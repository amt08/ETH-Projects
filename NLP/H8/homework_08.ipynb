{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10a023f",
   "metadata": {},
   "source": [
    "# HW06: Word Embeddings\n",
    "\n",
    "Remember that these homework work as a completion grade. **In this homework, we present two tasks and you can choose which one you want to solve. You only have to solve <span style=\"color:red\">one task</span> in this homework.**\n",
    "Task 1 is more guided and we evaluate document embeddings on a standard benchmark. Task 2 is very open-end and might be a starting point for your course project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3e6c9",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "In this task, we evaluate different document embeddings on the English version of the [STS Benchmark](https://arxiv.org/pdf/1708.00055.pdf). The task is to determine how semantically similar two texts are and is a popular dataset to evaluate document embeddings, i.e. we want embeddings of two semantically similar documents to be similar as well. We provide a wordcounts baseline for this task and ask you to compute and evaluate embeddings for a selected sample of document embedding techniques.\n",
    "\n",
    "To evaluate, we follow [(Reimers and Gurevych, 2019)](https://arxiv.org/pdf/1908.10084.pdf) and compute the Spearmanâ€™s rank correlation between the cosine-similarity of the sentence embeddings and the gold labels. **It is ok to skip one of the document embedding methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f00a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
    "\n",
    "!unzip sts2017.eval.v1.1.zip \n",
    "!unzip sts2017.gs.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee85334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "def load_STS_data():\n",
    "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
    "        labels = [float(line.strip()) for line in f]\n",
    "    \n",
    "    text_a, text_b = [], []\n",
    "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            text_a.append(line[0])\n",
    "            text_b.append(line[1])\n",
    "    return text_a, text_b, labels\n",
    "\n",
    "text_a, text_b, labels = load_STS_data()\n",
    "text_a[0], text_b[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils\n",
    "from scipy.stats import spearmanr\n",
    "def evaluate(predictions, labels):\n",
    "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b754bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcounts baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(text_a + text_b)\n",
    "\n",
    "# encode documents\n",
    "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
    "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from random import shuffle\n",
    "\n",
    "docs_a = []\n",
    "docs_b = []\n",
    "\n",
    "def tokenize(data):\n",
    "    docs = []\n",
    "    for item in data:\n",
    "        docs += [word_tokenize(item)]\n",
    "    return docs\n",
    "\n",
    "docs_a = tokenize(text_a)\n",
    "docs_b = tokenize(text_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO train Doc2Vec on the texts in the dataset\n",
    "##TODO derive the word vectors for each text in the dataset\n",
    "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
    "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "doc_iterator_a = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs_a)]\n",
    "doc_iterator_b = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs_b)]\n",
    "\n",
    "d2v_a = Doc2Vec(doc_iterator_a, min_count = 10,\n",
    "                window = 5, vector_size = 50,\n",
    "                sample = 1e-4, negative = 5,\n",
    "                worker = 4, max_vocab_size = 1000)\n",
    "\n",
    "\n",
    "d2v_b = Doc2Vec(doc_iterator_b, min_count = 10,\n",
    "                window = 5, vector_size = 50,\n",
    "                sample = 1e-4, negative = 5,\n",
    "                worker = 4, max_vocab_size = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fa123",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d2v_a.docvecs.vectors_docs\n",
    "b = d2v_b.docvecs.vectors_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96298d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [cosine_similarity(t1,t2) for t1,t2 in zip(a, b)]\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with embeddings provided by spaCy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "documents_a = [nlp(item) for item in text_a]\n",
    "documents_b = [nlp(item) for item in text_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [cosine_similarity(t1.vector,t2.vector) for t1,t2 in zip(documents_a, documents_b)]\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with universal sentence embeddings\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "\n",
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf333a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_a = []\n",
    "embeddings_b = []\n",
    "\n",
    "text_ue_a = []\n",
    "text_ue_b = []\n",
    "\n",
    "for i, item in enumerate(text_a):\n",
    "    embeddings_a.append(embed([item]))\n",
    "    \n",
    "for i, item in enumerate(text_b):\n",
    "    embeddings_b.append(embed([item]))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    for item in embeddings_a:\n",
    "        text_ue_a.append(session.run(item))\n",
    "    for item in embeddings_b:\n",
    "        text_ue_b.append(session.run(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [cosine_similarity(t1[0],t2[0]) for t1,t2 in zip(text_ue_a, text_ue_b)]\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b97372",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with SBERT embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = \"bert-base-nli-mean-tokens\"\n",
    "embedder = SentenceTransformer(model)\n",
    "text_encoded_a = []\n",
    "text_encoded_b = []\n",
    "for i, item in enumerate(text_a):\n",
    "    text_encoded_a.append(embedder.encode(item))\n",
    "    \n",
    "for i, item in enumerate(text_b):\n",
    "    text_encoded_b.append(embedder.encode(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [cosine_similarity(t1,t2) for t1,t2 in zip(text_encoded_a, text_encoded_b)]\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6ee63",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "Use your favorite document embeddings method to compute embeddings for a dataset you are interested in. Think of a method and provide some data visualization statistics (one method would be the path we have chosen in the notebook, i.e. cluster the embeddings with k-means and visualize low-dimensional representations of the document embeddings obtained by PCA). \n",
    "\n",
    "This task is very open and there is no right or wrong; If you want to use document embeddings in your course project, this is a chance to play around with them.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c46f5ccc24ef453e97fd721763d326d36913f44a8394821f5f9ff49f0aa076c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
