{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import exposure\n",
    "from skimage.morphology import erosion, dilation, opening, closing, disk, square, square\n",
    "\n",
    "from PIL import Image\n",
    "from kornia.filters import MedianBlur\n",
    "\n",
    "from albumentations.augmentations.transforms import HueSaturationValue, RandomBrightness, RandomContrast, Flip, Normalize\n",
    "from albumentations.augmentations import Resize, CLAHE\n",
    "from albumentations.augmentations import CenterCrop\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations.augmentations import Rotate\n",
    "from albumentations.augmentations.geometric.transforms import Affine\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from beepy import beep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seeds\n",
    "seed_value = 1508\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "TRAINING = True\n",
    "MAX_EPOCH = 40\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")\n",
    "\n",
    "split_index = 60\n",
    "\n",
    "# split data\n",
    "train = train_data[0:split_index] # 56 # 46 is first expert\n",
    "validation = train_data[split_index:] # collect only expert labels for val\n",
    "\n",
    "# prepare data for dataloader\n",
    "X_train = []\n",
    "y_train = []\n",
    "name_train = []\n",
    "\n",
    "for idx, img in enumerate(train):\n",
    "    frames = img['frames']\n",
    "    for frame in frames:\n",
    "        X_train.append(img['video'][:, :, frame])\n",
    "        y_train.append(img['label'][:, :, frame])\n",
    "        name_train.append(img['name'])\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "name_val = []\n",
    "\n",
    "for idx, img in enumerate(validation):\n",
    "    frames = img['frames']\n",
    "    for frame in frames:\n",
    "        X_val.append(img['video'][:, :, frame])\n",
    "        y_val.append(img['label'][:, :, frame])\n",
    "        name_val.append(img['name'])\n",
    "        \n",
    "X_test = []\n",
    "y_test = []\n",
    "name_test = []\n",
    "\n",
    "for idx, img in enumerate(test_data):\n",
    "    for frame in range(img['video'].shape[2]):\n",
    "        X_test.append(img['video'][:, :, frame])\n",
    "        y_test.append(np.zeros_like(img['video'][:, :, frame]))\n",
    "        name_test.append(img['name'])\n",
    "\n",
    "val_targets = []\n",
    "for itm in validation:\n",
    "    val_targets.append({'name': itm['name'], 'label': itm['label'][:, :, itm['frames']]})\n",
    "    \n",
    "train_targets = []\n",
    "for itm in train:\n",
    "    train_targets.append({'name': itm['name'], 'label': itm['label'][:, :, itm['frames']]})\n",
    "    \n",
    "sub_targets = []\n",
    "for itm in test_data:\n",
    "    sub_targets.append({'name': itm['name'], 'label': np.zeros_like(itm['video'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, angles):\n",
    "        self.angles = angles\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = self.angles\n",
    "        return TF.rotate(x, angle)\n",
    "\n",
    "rotation_transform = RotationTransform(angles=15)\n",
    "\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.abs((torch.randn(tensor.size()) * self.std + self.mean)/10.)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed_value)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, inputs, labels, name, augmentation=False):\n",
    "        self.img_labels = labels\n",
    "        self.img = inputs\n",
    "        self.name = name\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        \n",
    "        if self.augmentation:\n",
    "            transf_img = transforms.Compose([AddGaussianNoise()])\n",
    "            \n",
    "            transf_img_alb = Compose([\n",
    "                                    OneOf([\n",
    "                                               RandomBrightness(limit=0.3),\n",
    "                                               RandomContrast(limit=0.4)\n",
    "                                           ], p=1)])\n",
    "            \n",
    "            transf_img_alb_mask = Compose([\n",
    "                                        OneOf([\n",
    "                                                Affine(shear=1)\n",
    "                                               ], p=1)])\n",
    "            \n",
    "            transf = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.CenterCrop(image.shape[0]),\n",
    "                                        transforms.Resize(IMG_SIZE, interpolation=Image.NEAREST),\n",
    "                                           transforms.RandomChoice([\n",
    "                                               RotationTransform(angles=0),\n",
    "                                               RotationTransform(angles=5),\n",
    "                                               RotationTransform(angles=-5),\n",
    "                                               RotationTransform(angles=10),\n",
    "                                               RotationTransform(angles=-10),\n",
    "                                               transforms.RandomAffine(degrees=(0, 0), shear=(10, 10)),\n",
    "                                               transforms.RandomAffine(degrees=(0, 0), shear=(-10, -10))\n",
    "                                           ])\n",
    "                                         ])\n",
    "\n",
    "        else:\n",
    "            transf = transforms.Compose([transforms.ToTensor(),\n",
    "                                           transforms.CenterCrop(image.shape[0]),\n",
    "                                           transforms.Resize(IMG_SIZE, interpolation=Image.NEAREST)\n",
    "                                         ])\n",
    "        \n",
    "        \n",
    "        stacked = np.dstack([image, label])\n",
    "        stacked = transf(stacked)\n",
    "        img, label = torch.chunk(stacked, chunks=2, dim=0)\n",
    "            \n",
    "        if self.augmentation:\n",
    "            \n",
    "            img = img.cpu().detach().numpy()\n",
    "            img = transf_img_alb(image=img)\n",
    "            img = torch.tensor(img['image'])\n",
    "            \n",
    "            img = transf_img(img)\n",
    "            \n",
    "            #print(\"-\"*20)\n",
    "            \n",
    "            img[img > 1.] = 1\n",
    "            img[img < 0.] = 0\n",
    "            \n",
    "        \n",
    "        video_name = self.name[idx]\n",
    "        return img, label.bool().float(), video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(X_train, y_train, name_train, augmentation=True)\n",
    "training_data_for_eval = CustomImageDataset(X_train, y_train, name_train, augmentation=False)\n",
    "validation_data = CustomImageDataset(X_val, y_val, name_val, augmentation=False)\n",
    "testing_data = CustomImageDataset(X_test, y_test, name_test, augmentation=False)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, worker_init_fn=seed_worker, generator=g)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "# no augmentation\n",
    "train_dataloader_for_eval = DataLoader(training_data_for_eval, batch_size=1, shuffle=False, drop_last=False, worker_init_fn=seed_worker, generator=g)\n",
    "val_dataloader_for_eval = DataLoader(validation_data, batch_size=1, shuffle=False, drop_last=False, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "test_dataloader_for_submission = DataLoader(testing_data, batch_size=1, shuffle=False, drop_last=False, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, _ = next(iter(train_dataloader))\n",
    "print(f\"Feature train batch shape: {train_features.size()}\")\n",
    "print(f\"Labels train batch shape: {train_labels.size()}\")\n",
    "print(\"-\"*50)\n",
    "val_features, val_labels, _ = next(iter(val_dataloader))\n",
    "print(f\"Feature val batch shape: {val_features.size()}\")\n",
    "print(f\"Labels val batch shape: {val_labels.size()}\")\n",
    "\n",
    "test_idx = 1\n",
    "\n",
    "img = train_features[test_idx].squeeze()\n",
    "print(img.min(), img.max())\n",
    "\n",
    "img_m = train_labels[test_idx].squeeze()\n",
    "print(img_m.min(), img_m.max())\n",
    "\n",
    "img_merge = img.clone()\n",
    "img_merge[img_m.bool()] = 1\n",
    "print(img_merge.min(), img_merge.max())\n",
    "\n",
    "f, axarr = plt.subplots(1, 3, figsize=(15, 3))\n",
    "axarr[0].imshow(img, cmap='gray')\n",
    "axarr[1].imshow(img_m, cmap='gray')\n",
    "axarr[2].imshow(img_merge, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "    \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    # BW\n",
    "    model = UNet(1, 1).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    min_valid_loss = np.inf\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        for data in train_dataloader:\n",
    "\n",
    "            # get inputs\n",
    "            inputs, labels, names = data\n",
    "            \n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # send to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the params gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward, backward, optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss_bce = criterion(outputs, labels)\n",
    "            loss_iou = iou_score(outputs, labels)\n",
    "            loss = loss_bce * 0.5 + (iou_score * -0.5 + 0.5)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # print loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "\n",
    "        for data_val in val_dataloader:\n",
    "\n",
    "            # get inputs\n",
    "            inputs_val, labels_val, names_val = data\n",
    "\n",
    "            # send to device\n",
    "            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "\n",
    "            target_val = model(inputs_val)\n",
    "            \n",
    "            loss_val = criterion(target_val, labels_val) \n",
    "            loss_iou_val = iou_score(target_val, labels_val)\n",
    "            loss_val = loss_val * 0.5 + loss_iou_val * 0.5\n",
    "            valid_loss += loss_val.item() * inputs_val.size(0)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_dataloader))\n",
    "        val_losses.append(valid_loss / len(val_dataloader))\n",
    "\n",
    "        print(f'Epoch {epoch+1} \\t\\t Training loss: {train_loss / len(train_dataloader)} \\t\\t Validation loss: {valid_loss / len(val_dataloader)}')\n",
    "\n",
    "        if min_valid_loss > (valid_loss/len(val_dataloader)):\n",
    "\n",
    "            print(f'Validation Loss Decreased({min_valid_loss: .6f}----->{valid_loss/len(val_dataloader):.6f}) \\t Saving the model..')\n",
    "            min_valid_loss = (valid_loss/len(val_dataloader))\n",
    "\n",
    "            # save model\n",
    "            torch.save(model.state_dict(), 'unet_min.pth')\n",
    "            \n",
    "        if epoch % 5 == 0 and epoch > 0:\n",
    "            torch.save(model.state_dict(), 'unet_' + str(epoch) + '.pth')\n",
    "\n",
    "    \n",
    "    print('Finished Training')\n",
    "    torch.save(model.state_dict(), 'unet.pth')\n",
    "\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.show()\n",
    "    \n",
    "    beep(4)\n",
    "\n",
    "else:\n",
    "    print(\"Training skipped...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "def test_net(test_dataloader, net_name):\n",
    "    mask = []\n",
    "    mask_aux = []\n",
    "    \n",
    "    for data in tqdm(test_dataloader):\n",
    "\n",
    "        # get inputs\n",
    "        inputs_test, labels_test, names_test = data\n",
    "\n",
    "        # send to device\n",
    "        inputs_test, labels_test = inputs_test.to('cpu'), labels_test.to('cpu')\n",
    "\n",
    "        # load best model\n",
    "        unet = UNet(1, 1).to('cpu')\n",
    "        unet.load_state_dict(torch.load(net_name))\n",
    "        unet.eval()\n",
    "\n",
    "        # predict test data\n",
    "        target_test = unet(inputs_test)\n",
    "\n",
    "        # apply sigmoid to predictions\n",
    "        preds_test = torch.sigmoid(target_test)\n",
    "\n",
    "        mask.append({\n",
    "                'name': names_test[0],\n",
    "                'prediction': (preds_test.cpu() > 0.5).float()\n",
    "        })\n",
    "\n",
    "        mask_aux.append({\n",
    "                'name': names_test[0],\n",
    "                'input': inputs_test.cpu(),\n",
    "                'label': labels_test.cpu()\n",
    "        })\n",
    "\n",
    "    return mask, mask_aux\n",
    "\n",
    "def show_masks(mask, mask_aux):\n",
    "    for test_ind in range(0, 15):\n",
    "        f, axarr = plt.subplots(1, 3, figsize=(10, 3))\n",
    "        axarr[2].imshow(mask[test_ind]['prediction'].detach().numpy().squeeze(0).squeeze(0), cmap='gray')\n",
    "        axarr[0].imshow(mask_aux[test_ind]['input'].detach().numpy().squeeze(0).squeeze(0), cmap='gray')\n",
    "        axarr[1].imshow(mask_aux[test_ind]['label'].detach().numpy().squeeze(0).squeeze(0), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "net_name_to_test = 'unet_25.pth'\n",
    "val_mask, val_mask_aux = test_net(val_dataloader_for_eval, net_name_to_test)\n",
    "train_mask, train_mask_aux = test_net(train_dataloader_for_eval, net_name_to_test)\n",
    "sub_mask, sub_mask_aux = test_net(test_dataloader_for_submission, net_name_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# postprocessing\n",
    "def postprocess(prd, label, image, show=False):\n",
    "    pred = prd.numpy().squeeze(0).squeeze(0)\n",
    "    label = label.numpy().squeeze(0).squeeze(0)\n",
    "    image = image.numpy().squeeze(0).squeeze(0)\n",
    "    \n",
    "    # threshold on original image\n",
    "    image_th = (image*255 > 30).astype(float)\n",
    "    # erode mask\n",
    "    erosion_square = square(2) # slightly better with just erosion 2\n",
    "    pred = erosion(pred, erosion_square)\n",
    "    # return to tensor\n",
    "    pred = torch.tensor(pred).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    if show:\n",
    "        f, axarr = plt.subplots(1, 5, figsize=(15, 3))\n",
    "        axarr[0].imshow(image, cmap='gray')\n",
    "        axarr[1].imshow(image_th, cmap='gray')\n",
    "        axarr[2].imshow(label, cmap='gray')\n",
    "        axarr[3].imshow(prd.numpy().squeeze(0).squeeze(0), cmap='gray')\n",
    "        axarr[4].imshow(pred, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def postprocess_dataset(dataset, dataset_aux):\n",
    "    for index in tqdm(range(0, len(dataset))):\n",
    "        dataset[index]['prediction'] = postprocess(dataset[index]['prediction'],\n",
    "                                                   dataset_aux[index]['label'],\n",
    "                                                   dataset_aux[index]['input'])\n",
    "    return dataset\n",
    "        \n",
    "val_mask = postprocess_dataset(val_mask, val_mask_aux)\n",
    "train_mask = postprocess_dataset(train_mask, train_mask_aux)\n",
    "sub_mask = postprocess_dataset(sub_mask, sub_mask_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate(predictions, targets):\n",
    "    ious = []\n",
    "    for p, t in zip(predictions, targets):\n",
    "        assert p['name'] == t['name']\n",
    "        prediction = np.array(p['prediction'], dtype=bool)\n",
    "        target = np.array(t['label'], dtype=bool)\n",
    "\n",
    "        assert target.shape == prediction.shape\n",
    "        overlap = prediction * target\n",
    "        union = prediction + target\n",
    "\n",
    "        ious.append(overlap.sum()/float(union.sum()))\n",
    "    \n",
    "    print(\"\\nMedian IOU:\", round(np.median(ious), 3))\n",
    "    print(\"\\nMean IOU:  \", round(np.mean(ious), 3))\n",
    "    print(\"\\nMin IOU:   \", round(np.min(ious), 3))\n",
    "    print(\"Q10 IOU:   \", round(np.quantile(ious, 0.10), 3))\n",
    "    print(\"Q15 IOU:   \", round(np.quantile(ious, 0.15), 3))\n",
    "    print(\"Q25 IOU:   \", round(np.quantile(ious, 0.25), 3))\n",
    "    print(\"Q40 IOU:   \", round(np.quantile(ious, 0.40), 3))\n",
    "    print(\"Q50 IOU:   \", round(np.quantile(ious, 0.50), 3))\n",
    "    print(\"Q75 IOU:   \", round(np.quantile(ious, 0.75), 3))\n",
    "    print(\"Max IOU:   \", round(np.max(ious), 3))\n",
    "\n",
    "\n",
    "def search_by_name(name, dataset):\n",
    "    for idx, item in enumerate(dataset):\n",
    "        if item['name'] == name:\n",
    "            return (idx, item)\n",
    "    return None\n",
    "\n",
    "def revert_changes(img, size):\n",
    "    \n",
    "    img = np.array(img.squeeze(0).squeeze(0))\n",
    "    img = resize(img, (size[0], size[0]))\n",
    "    \n",
    "    size_diff = size[1] - size[0]\n",
    "    left_pad = int(size_diff / 2)\n",
    "    if size_diff % 2 == 0:\n",
    "        right_pad = int(size_diff / 2)\n",
    "    else:\n",
    "        right_pad = int(size_diff / 2) + 1\n",
    "    \n",
    "    img = np.pad(img, ((0, 0), (left_pad, right_pad)))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def revert_mask(mask, target):\n",
    "    mask_reverted = []\n",
    "    for mask_item in mask:\n",
    "        target_size = search_by_name(mask_item['name'], target)[1]['label'].shape[:2]\n",
    "        mask_reverted.append({'name': mask_item['name'],\n",
    "                            'prediction': revert_changes(mask_item['prediction'], target_size)})\n",
    "    return mask_reverted\n",
    "\n",
    "def get_predictions(mask, target):\n",
    "    predictions = []\n",
    "    for rev_item in tqdm(revert_mask(mask, target)):\n",
    "        search = search_by_name(rev_item['name'], predictions)\n",
    "        if search:\n",
    "            pred = predictions[search[0]]\n",
    "            pred['prediction'] = np.dstack([pred['prediction'], rev_item['prediction'].astype(bool)])\n",
    "            predictions[search[0]] = pred\n",
    "        else:\n",
    "            predictions.append({'name': rev_item['name'], 'prediction': rev_item['prediction'].astype(bool)})\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "val_predictions = get_predictions(val_mask, val_targets)\n",
    "train_predictions = get_predictions(train_mask, train_targets)\n",
    "sub_predictions = get_predictions(sub_mask, sub_targets)\n",
    "        \n",
    "print('VALIDATION SCORE:')\n",
    "evaluate(val_predictions, val_targets)\n",
    "print('\\nTRAINING SCORE:')\n",
    "evaluate(train_predictions, train_targets)\n",
    "print('\\nSUBMISSION MOCK SCORE:')\n",
    "evaluate(sub_predictions, sub_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)\n",
    "        \n",
    "save_zipped_pickle(sub_predictions, 'submission.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_mask_aux[0]['input'].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "f, axarr = plt.subplots(1, 3, figsize=(10, 3))\n",
    "axarr[0].imshow(val_mask_aux[idx]['input'].squeeze(), cmap='gray')\n",
    "axarr[1].imshow(val_mask_aux[idx]['label'].squeeze(), cmap='gray')\n",
    "axarr[2].imshow(val_mask[idx]['prediction'].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "39b5c16b68b67ba22346ef6d698bf62f4f1e91a475e577be2818f6d4b05b72b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
