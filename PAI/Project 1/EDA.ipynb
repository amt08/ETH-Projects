{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mq_8mZjmi9mz"
   },
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process as gp\n",
    "import os\n",
    "import typing\n",
    "\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.kernel_approximation import  Nystroem, RBFSampler\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Wip_YiYjJ10",
    "outputId": "57a3ebf0-2467-4d7b-91e3-9d551822402a"
   },
   "outputs": [],
   "source": [
    "#%cd /content/drive/My Drive/Task1PAI/Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfJtayWjsOua"
   },
   "outputs": [],
   "source": [
    "# Cost function constants\n",
    "THRESHOLD = 35.5\n",
    "COST_W_NORMAL = 1.0\n",
    "COST_W_OVERPREDICT = 5.0\n",
    "COST_W_THRESHOLD = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pm7cEOnmrtpU"
   },
   "outputs": [],
   "source": [
    "def cost_function(y_true: np.ndarray, y_predicted: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the cost of a set of predictions.\n",
    "\n",
    "    :param y_true: Ground truth pollution levels as a 1d NumPy float array\n",
    "    :param y_predicted: Predicted pollution levels as a 1d NumPy float array\n",
    "    :return: Total cost of all predictions as a single float\n",
    "    \"\"\"\n",
    "    assert y_true.ndim == 1 and y_predicted.ndim == 1 and y_true.shape == y_predicted.shape\n",
    "\n",
    "    # Unweighted cost\n",
    "    cost = (y_true - y_predicted) ** 2\n",
    "    weights = np.zeros_like(cost)\n",
    "\n",
    "    # Case i): overprediction\n",
    "    mask_1 = y_predicted > y_true\n",
    "    weights[mask_1] = COST_W_OVERPREDICT\n",
    "\n",
    "    # Case ii): true is above threshold, prediction below\n",
    "    mask_2 = (y_true >= THRESHOLD) & (y_predicted < THRESHOLD)\n",
    "    weights[mask_2] = COST_W_THRESHOLD\n",
    "\n",
    "    # Case iii): everything else\n",
    "    mask_3 = ~(mask_1 | mask_2)\n",
    "    weights[mask_3] = COST_W_NORMAL\n",
    "\n",
    "    # Weigh the cost and return the average\n",
    "    return np.mean(cost * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-PtzNr2jCwK"
   },
   "outputs": [],
   "source": [
    "X_tr = np.loadtxt('train_x.csv', delimiter=',', skiprows=1)\n",
    "y_tr = np.loadtxt('train_y.csv', delimiter=',', skiprows=1)\n",
    "X_te = np.loadtxt('test_x.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "kjLaUKl0jYs5",
    "outputId": "690f41f8-c67c-46be-968a-93b482421adb"
   },
   "outputs": [],
   "source": [
    "# plot the training data\n",
    "plt.scatter(X_tr[:,0],X_tr[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "TcdyMyc_jlY3",
    "outputId": "c0c909af-0134-462b-e4f5-52e9469b7e3a"
   },
   "outputs": [],
   "source": [
    "# plot the test data\n",
    "plt.scatter(X_te[:, 0], X_te[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_training(X_tr, y_tr):\n",
    "    train_data = np.concatenate((X_tr, y_tr.reshape(-1, 1)), axis = 1)\n",
    "    np.random.shuffle(train_data)\n",
    "    # only take 4000 observations\n",
    "    index = np.random.choice(train_data.shape[0], size = 4000, replace=False)\n",
    "    train = train_data[index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train[:, :2], train[:, 2], test_size = 0.3, random_state=0)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((X_tr, y_tr.reshape(-1, 1)), axis = 1)\n",
    "np.random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(train_data.shape[0], size = 3000, replace=False)\n",
    "train = train_data[index]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train[:, :2], train[:, 2], test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'length_scale': [0.1],\n",
    "          'noise_level': [0.005],\n",
    "          'alpha': [0.001],\n",
    "          'n_components': [200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train[:, :2]\n",
    "# y_train = train[:, 2].reshape(-1, 1)\n",
    "\n",
    "# TODO: Fit your model here\n",
    "\n",
    "kernel= RBF(length_scale=params['length_scale']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "gpr_p = pipeline.Pipeline([\n",
    "                (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], \n",
    "                                                 random_state=0, normalize_y=True))])\n",
    "gpr_p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBFSampler and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_zdP29Qoy0R",
    "outputId": "c4237ed3-bfdc-4e5b-f62e-92982f57d640"
   },
   "outputs": [],
   "source": [
    "# params = {'nu': [0.1, 0.5, 1],\n",
    "#           'noise_level': [0.01, 0.05, 0.1, 0.5],\n",
    "#           'alpha': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "# params = {'length_scale': [0.5,0.1],# 0.1, 10, 100],\n",
    "#           'noise_level': [0.1, 0.05],\n",
    "#           'alpha': [0.1, 0.05, 0.001]}#, 0.05, 1, 2, 5, 10]}\n",
    "\n",
    "# params = {'length_scale': [0.1, 0.01],# 0.1, 10, 100],\n",
    "#           'noise_level': [0.1, 0.01],\n",
    "#           'alpha': [0.1, 0.05, 0.01]}#, 0.05, 1, 2, 5, 10]}\n",
    "\n",
    "params = {'length_scale': [0.01],\n",
    "          'noise_level': [0.1],\n",
    "          'alpha': [0.05],\n",
    "          'offset': [-2]} # [-1, -2]\n",
    "\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: y_hat > y\n",
    "# 20: y >= threshold > y_hat\n",
    "# 1:  \n",
    "#     y >= y_hat >= threshold\n",
    "#     threshold > y >= y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for params in tqdm(grid):\n",
    "    kernel= RBF(length_scale=params['length_scale']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "    gpr_p = pipeline.Pipeline([\n",
    "#                     (\"scale\", StandardScaler()),\n",
    "                    (\"sampler\", RBFSampler(random_state=0, n_components=200)),\n",
    "                    (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'],\n",
    "                                                     random_state=0, normalize_y=True))])\n",
    "    gpr_p.fit(X_train, y_train)\n",
    "    pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "    pred_mean += params['offset']\n",
    "    mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "#     mask2 = ((pred_mean - THRESHOLD >= 0) & (pred_mean - THRESHOLD <= 5))\n",
    "    pred_mean[mask1] = THRESHOLD\n",
    "#     pred_mean[mask2] = THRESHOLD\n",
    "#     lower_mask = pred_mean <= np.percentile(pred_mean, 25)\n",
    "#     upper_mask =pred_mean >= np.percentile(pred_mean, 75)\n",
    "#     pred_mean[upper_mask] = pred_mean[upper_mask] - (THRESHOLD/2)\n",
    "    costs.append(cost_function(y_val, pred_mean))\n",
    "    \n",
    "costs, grid[np.argmin(costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nystrom approx and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'nu': [0.1, 0.5, 1],\n",
    "#           'noise_level': [0.01, 0.05, 0.1, 0.5],\n",
    "#           'alpha': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "# params = {'length_scale': [0.5,0.1],# 0.1, 10, 100],\n",
    "#           'noise_level': [0.1, 0.05],\n",
    "#           'alpha': [0.1, 0.05, 0.001]}#, 0.05, 1, 2, 5, 10]}\n",
    "\n",
    "# params = {'length_scale': [0.05, 0.1],# 0.1, 10, 100],\n",
    "#           'noise_level': [0.005, 0.001],\n",
    "#           'alpha': [0.001, 0.005],\n",
    "#            'n_components': [100, 200, 300]}#, 0.05, 1, 2, 5, 10]}\n",
    "\n",
    "params = {'length_scale': [0.1],# 0.1, 10, 100],\n",
    "          'noise_level': [0.005],\n",
    "          'alpha': [0.001],\n",
    "           'n_components': [200],\n",
    "           'offset': [-2]}#, 0\n",
    "\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost_iterations = []\n",
    "# for i in tqdm(range(5)):\n",
    "#     X_train, X_val, y_train, y_val = sample_training(X_tr, y_tr)\n",
    "    \n",
    "#     costs = []\n",
    "#     for params in tqdm(grid):\n",
    "#         kernel= RBF(length_scale=params['length_scale']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "#         gpr_p = pipeline.Pipeline([\n",
    "#                         (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "#                         (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], n_restarts_optimizer=5,\n",
    "#                                                          random_state=0, normalize_y=True))])\n",
    "#         gpr_p.fit(X_train, y_train)\n",
    "#         pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "#         pred_mean += params['offset']\n",
    "#         mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "#         pred_mean[mask1] = THRESHOLD\n",
    "#         costs.append(cost_function(y_val, pred_mean))\n",
    "\n",
    "#     costs, grid[np.argmin(costs)]\n",
    "#     cost_iterations.append(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugDtX5oHz7wO",
    "outputId": "3f280b58-d2aa-4a09-8ce8-67ddb5187eb9"
   },
   "outputs": [],
   "source": [
    "# n_restarts_optimizer=5,\n",
    "grid = ParameterGrid(params)\n",
    "costs = []\n",
    "for params in tqdm(grid):\n",
    "    print(params)\n",
    "    kernel= RBF(length_scale=params['length_scale']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "    gpr_p = pipeline.Pipeline([\n",
    "                    (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                    (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], \n",
    "                                                     random_state=0, normalize_y=True))])\n",
    "    gpr_p.fit(X_train, y_train)\n",
    "    pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "    pred_mean += params['offset']\n",
    "    mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "    pred_mean[mask1] = THRESHOLD\n",
    "    costs.append(cost_function(y_val, pred_mean))\n",
    "    \n",
    "costs, grid[np.argmin(costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF, Constant and White kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'nu': [0.1, 0.5, 1],\n",
    "#           'noise_level': [0.01, 0.05, 0.1, 0.5],\n",
    "#           'alpha': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "# params = {'length_scale': [0.5,0.1],# 0.1, 10, 100],\n",
    "#           'noise_level': [0.1, 0.05],\n",
    "#           'alpha': [0.1, 0.05, 0.001]}#, 0.05, 1, 2, 5, 10]}\n",
    "\n",
    "# params = {'length_scale': [0.05, 0.1],# 0.1, 10, 100],\n",
    "#           'noise_level': [0.005, 0.001],\n",
    "#           'alpha': [0.001, 0.005],\n",
    "#            'n_components': [100, 200, 300]}#, 0.05, 1, 2, 5, 10]}\n",
    "\n",
    "params = {'length_scale': [0.1],# 0.1, 10, 100],\n",
    "          'noise_level': [0.005],\n",
    "          'alpha': [0.001],\n",
    "          'n_components': [200],\n",
    "          'offset': [-2]}\n",
    "\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for params in tqdm(grid):\n",
    "    kernel= ConstantKernel(1) * RBF(length_scale=params['length_scale']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "    gpr_p = pipeline.Pipeline([\n",
    "                    (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                    (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], n_restarts_optimizer=5,\n",
    "                                                     random_state=0, normalize_y=True))])\n",
    "    gpr_p.fit(X_train, y_train)\n",
    "    pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "    pred_mean += params['offset']\n",
    "    mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "    pred_mean[mask1] = THRESHOLD\n",
    "    costs.append(cost_function(y_val, pred_mean))\n",
    "    \n",
    "costs, grid[np.argmin(costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mattern Kernel and White Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'nu': [1.5, 2.5],\n",
    "#           'length_scale': [0.1, 0.5],\n",
    "#           'noise_level': [0.01, 0.001],\n",
    "#           'alpha': [0.01],\n",
    "#            'n_components': [50, 100]}\n",
    "\n",
    "params = {'nu': [2.5],\n",
    "          'length_scale': [0.5],\n",
    "          'noise_level': [0.001],\n",
    "          'alpha': [0.01],\n",
    "           'n_components': [100],\n",
    "          'offset': [-2]}\n",
    "\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_iterations = []\n",
    "for i in tqdm(range(5)):\n",
    "    X_train, X_val, y_train, y_val = sample_training(X_tr, y_tr)\n",
    "    \n",
    "    costs = []\n",
    "    for params in tqdm(grid):\n",
    "        kernel= Matern(length_scale=params['length_scale'], nu=params['nu']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "        gpr_p = pipeline.Pipeline([\n",
    "                        (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                        (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], n_restarts_optimizer=5,\n",
    "                                                         random_state=0, normalize_y=True))])\n",
    "        gpr_p.fit(X_train, y_train)\n",
    "        pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "        pred_mean += params['offset']\n",
    "        mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "        pred_mean[mask1] = THRESHOLD\n",
    "        costs.append(cost_function(y_val, pred_mean))\n",
    "\n",
    "    costs, grid[np.argmin(costs)]\n",
    "    cost_iterations.append(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cost_iterations), cost_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for params in tqdm(grid):\n",
    "    kernel= Matern(length_scale=params['length_scale'], nu=params['nu']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "    gpr_p = pipeline.Pipeline([\n",
    "                    (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                    (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], n_restarts_optimizer=5,\n",
    "                                                     random_state=0, normalize_y=True))])\n",
    "    gpr_p.fit(X_train, y_train)\n",
    "    pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "    pred_mean += params['offset']\n",
    "    mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "    pred_mean[mask1] = THRESHOLD\n",
    "    costs.append(cost_function(y_val, pred_mean))\n",
    "    \n",
    "costs, grid[np.argmin(costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of multiple Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF + Matern + WhiteNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'nu': [1.5, 2.5],\n",
    "#           'length_scale': [0.1, 0.5],\n",
    "#           'noise_level': [0.01, 0.001],\n",
    "#           'alpha': [0.01],\n",
    "#            'n_components': [50, 100]}\n",
    "\n",
    "# params = {'nu': [2.5, 1.5],\n",
    "#           'length_scale': [0.5],\n",
    "#           'noise_level': [0.001],\n",
    "#           'alpha': [0.01, 0.01],\n",
    "#            'n_components': [200]}\n",
    "# #           'offset': [-1, -2]}\n",
    "\n",
    "params = {'nu': [2.5],\n",
    "          'length_scale': [0.5],\n",
    "          'noise_level': [0.001],\n",
    "          'alpha': [0.01],\n",
    "           'n_components': [200]}\n",
    "#           'offset': [-1, -2]}\n",
    "\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for params in tqdm(grid):\n",
    "    kernel= RBF(length_scale=params['length_scale']) + Matern(length_scale=params['length_scale'], nu=params['nu']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "    gpr_p = pipeline.Pipeline([\n",
    "                    (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                    (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], n_restarts_optimizer=5,\n",
    "                                                     random_state=0, normalize_y=True))])\n",
    "    gpr_p.fit(X_train, y_train)\n",
    "    pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "#     pred_mean += params['offset']\n",
    "#     mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "#     pred_mean[mask1] = THRESHOLD\n",
    "    costs.append(cost_function(y_val, pred_mean))\n",
    "    \n",
    "costs, grid[np.argmin(costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF + RationalQuadratic +WhiteNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'nu': [1.5, 2.5],\n",
    "#           'length_scale': [0.1, 0.5],\n",
    "#           'noise_level': [0.01, 0.001],\n",
    "#           'alpha': [0.01],\n",
    "#            'n_components': [50, 100]}\n",
    "\n",
    "params = {'nu': [2.5],\n",
    "          'length_scale': [0.5, 0.1],\n",
    "          'noise_level': [0.001],\n",
    "          'alpha': [0.001, 0.01],\n",
    "          'mixture': [0.5, 1, 1.5],\n",
    "           'n_components': [200, 100]}\n",
    "#           'offset': [-1, -2]}\n",
    "\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for params in tqdm(grid):\n",
    "    kernel= RationalQuadratic(length_scale=params['length_scale'], alpha = params['mixture']) + Matern(length_scale=params['length_scale'], nu=params['nu']) + WhiteKernel(noise_level=params['noise_level'])\n",
    "    gpr_p = pipeline.Pipeline([\n",
    "                    (\"nystrom\", Nystroem(kernel = kernel, random_state=0, n_components=params['n_components'])),\n",
    "                    (\"gpr\", GaussianProcessRegressor(kernel=kernel, alpha = params['alpha'], n_restarts_optimizer=5,\n",
    "                                                     random_state=0, normalize_y=True))])\n",
    "    gpr_p.fit(X_train, y_train)\n",
    "    pred_mean, pred_std = gpr_p.predict(X_val, return_std=True)\n",
    "#     pred_mean += params['offset']\n",
    "#     mask1 = ((THRESHOLD - pred_mean >= 0) & (THRESHOLD - pred_mean <= 5))\n",
    "#     pred_mean[mask1] = THRESHOLD\n",
    "    costs.append(cost_function(y_val, pred_mean))\n",
    "    \n",
    "costs, grid[np.argmin(costs)]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EDA_Adnana.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "39b5c16b68b67ba22346ef6d698bf62f4f1e91a475e577be2818f6d4b05b72b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
